<p align="center">
<img src="https://media.giphy.com/media/IIWi4Qwtl5mM9JbMF4/giphy.gif" alt="animation1" />
</p>

<h2 align="center"> Accessio uses Machine Learning to understand the processes of everyday life - it learns how to get you from where you are, to where you want to be.<br><br></h2>
 
<h3>Disability specific examples</h3>
* Apply for a blue badge parking permit<br>
* Apply for Personal Independence Payments<br>
* Apply for a disabled person's bus pass
 
<h3>Broader examples</h3>
* Apply for a passport<br>
* Buy a house<br>
* Travel abroad during Covid<br><br>
 
Accessio finds relevant websites, reads, compares and summarises them, to create a step-by-step visual user journey map that guides you on what needs to be done, and when.
 
<h2>Technology</h2>

Using Artificial Intelligence, Accessio summarises text from numerous sources such as government documents, advice websites and online forums. 
 
Accessio uses Natural Language Processing algorithms, in a range of supervised and unsupervised models to break down text into instructions, and then maps these into a user journey map.
 
All of Accessio’s user journey maps use templates that are compatible with the latest accessibility technology - such as translation tools, screen readers and personalised display preferences - to support users with a range of accessibility needs.

To be built using Python, or Azure Machine Learning

<h3 align="center">Input: Text from numerous sources</h3>
<p align="center"> <img src="https://user-images.githubusercontent.com/61777002/145097309-abc181da-0d06-4bf6-9a81-ba5697a7b591.png" alt="still_inputs" /> </p>
<p align="center"> <img width="100" src="https://user-images.githubusercontent.com/61777002/145086586-ca25b590-6565-4a28-9a64-27fa1c3ff354.png" alt="plain_arrow" /> </p>
<h3 align="center">Process: Accessio Natural Language Processing Technology Stack</h3>
<p align="center">

 ![NLP Process Accessio](https://user-images.githubusercontent.com/61777002/145103951-4c10c050-a56c-4511-bd1f-aa6fba470f13.gif)

</p>
<p align="center"> <img width="100" src="https://user-images.githubusercontent.com/61777002/145086586-ca25b590-6565-4a28-9a64-27fa1c3ff354.png" alt="plain_arrow" /> </p>
<h3 align="center"> Example Output : User journey map of applying for a young person's Education, Health and Care Plan (UK) </h3>
<p align="center"><img width="1100" alt="[EHC Plan Application Process]" src="https://user-images.githubusercontent.com/61777002/145069264-c4410ab9-953c-4dbe-b0f8-2e536fd741d7.png"> <em>Click image to expand</em></p>

<h2>Summary</h2>
 
When starting a new process it can be difficult to understand the steps to follow. In an ever changing world, we can't always be certain what the latest procedure is. To overcome an information overload, Machine Learning helps us handle a growing deluge of documents, websites and forums.
 
There is an increasing number of data scientists using Natural Language Processing to advance tech’s ability to summarise text. Accessio is different because it focuses primarily on **procedural text**, and processing this into a user friendly, accessible **summarised, step-by-step output**.

---
<h1>Development</h1>
<h3>User Stories </h3>
<details open>
<summary>Basic</summary>

```
As a user,
I want to see a filtered list of relevant assistive technology funding opportunities, 
So I can narrow my applications to only the opportunities for which I am eligible.
```
```
As a user,
I want to compare funding opportunities in a table format,
So I can compare all relevant funding opportunities on one screen.
```
```
As a user,
I want to have a start to finish, step-by-step customer journey map of the application process,
So I have no surprises or requests for random pieces of information or evidence.
```
</details>

<h4>Disability specific</h4>
<details>
<summary>Keyboard-Only User</summary>

```
As keyboard-only user,
I want to be able to reach the main navigation links with a keyboard,
so that I can determine the different areas of the site.
```
```
As keyboard-only user,
I want the ability to reach all links (text or image), form controls and page functions,
so that I can perform an action or navigate to the place I choose.
```
```
As a keyboard-only user,
I want the ability to use the enter key to open the selected link,
so that every link on a page is accessible using a keyboard as it would be with a left mouse click.
```
```
As keyboard-only user,
I want to know where I am on the screen at all times,
so that I know what I can do and how to do it.
```
</details>
<details>
<summary>Screen Reader User</summary>

```
As a screen reader user,
I want to hear the text equivalent for each image conveying information,
so that I don’t miss any information on the page.
```
```
As a screen reader user,
I want to hear the text equivalent for each image button,
so that I will know what function it performs.
```
```
As a screen reader user,
I want to understand know what each form label is for each form field,
so that I can effectively enter the correct information in the form.
```
```
As a screen reader user,
I want to know what the column and row headers for each table cell,
so that I can understand the meaning of the data.
```
</details>
<details>
<summary>User with Low-Vision</summary>

```
As a user who has trouble reading due to low vision,
I want to be able to make the text larger on the screen,
so that I can read it.
```
</details>
<details>
<summary>User with Color-blindness</summary>

```
As a user who is color blind,
I want to have access to information conveyed in color,
so that I do not miss anything and I understand the content.
```
```
As a user who is color blind,
I want to links to be distinguishable on the page,
so that I can find the links and navigate the site.
```
```
As a user who is color blind,
I want to know what fields are required,
so that I can fill out the form.
```
</details>
<details>
<summary>Hearing Impaired User</summary>

```
As a user who is hearing-impaired,
I want a transcript of the spoken audio,
so that I can have access to all information provided in audio clips.
```
```
As a user who is hearing-impaired,
I want to turn on video captions,
so that I can understand what is being said in videos.
```
</details>
<h3>Learning & Resources</h3>
<h4>Accessibility & Assistive Technology</h4>
<h4>AI, Machine Learning, & Natural Language Processing</h4>
<details>
<summary>LinkedIn Learning, udemy & Makers Academy</summary>
<ul>
  <li><a href="https://www.linkedin.com/learning/nlp-with-python-for-machine-learning-essential-training/what-you-should-know?autoAdvance=true&autoSkip=true&autoplay=true&resume=false">NLP with Python for Machine Learning Essential Training</a></li>
<li><a href="https://www.linkedin.com/learning/unit-testing-and-test-driven-development-in-python/welcome?autoAdvance=true&autoSkip=false&autoplay=true&resume=true">Unit Testing & Test Driven Development in Python</a></li>
<li><a href="https://www.linkedin.com/learning/azure-machine-learning-development-1-basic-concepts/what-you-should-know?autoAdvance=true&autoSkip=true&autoplay=true&resume=false">Azure Machine Learning Development: 1 Basic Concepts</a></li>
<li><a href="https://www.linkedin.com/learning/advanced-nlp-with-python-for-machine-learning/leveraging-the-power-of-messy-text-data?autoAdvance=true&autoSkip=false&autoplay=true&resume=true">Advanced NLP with Python for Machine Learning</a></li>
<li><a href="https://www.linkedin.com/learning/design-thinking-data-intelligence/welcome?autoAdvance=true&autoSkip=false&autoplay=true&resume=true">Design Thinking: Data Intelligence</a></li>
<li><a href="https://www.linkedin.com/learning/deep-learning-foundations-natural-language-processing-with-tensorflow/leveraging-deep-learning-for-natural-language-processing?autoAdvance=true&autoSkip=false&autoplay=true&resume=true">Deep Learning Foundations: Natural Language Processing with TensorFlow</a></li>
<li><a href="https://www.udemy.com/course/django-python-advanced/">Build a Backend REST API with Python & Django - Advanced</a></li>
<li><a href="https://makersstudents.slack.com/archives/CJ94H1P6U">Makers Algorithm course - #Algorithm channel on Slack</a></li>
</ul>
</details>
<details>
<summary>Books</summary>
<ul>
<li><a href="https://www.manning.com/books/grokking-algorithms">'Algorithms', by Grokking</a></li>
<li><a href="https://automatetheboringstuff.com/">'Automate the boring stuff with Python', by Sweigart</a></li>
</ul>
</details>
<details>
<summary>Videos and Podcasts</summary>
<ul>
<li><a href="https://www.avclub.com/black-mirror-be-right-back-1798178877">Netflix - Black Mirror: “Be Right Back”</a></li>
<li><a href="https://law.unimelb.edu.au/news/caide/black-mirrors-hated-in-the-nation-facial-recognition-is-a-weapon">Netflix - Black Mirror: “Hated in the Nation”</a></li>
<li><a href="https://www.bbc.co.uk/sounds/play/m001216j">BBC iPlayer, The Reith Lectures, Stuart Russell - Living With Artificial Intelligence</a></li>
</ul>
</details>
<h3>Machine Learning Workflow</h3>

![Screenshot 2021-12-07 at 22 26 51](https://user-images.githubusercontent.com/61777002/145180303-22a92b9c-6d0d-4aee-a778-f0fcb40e6394.png)
<br>Source: [Google Cloud tutorial](https://cloud.google.com/ai-platform/docs/ml-solutions-overview?utm_source=youtube&utm_medium=unpaidsoc&utm_campaign=CDR_guo_aiml_nkw8ndu7mjw_010521&utm_content=description 
)

<details open>
<summary>Source and prepare your data (Step 1 of 7)</summary>
 Currently here!
</details>

<details>
<summary>Code your model (Step 2 of 7)</summary>
</details>

<details>
<summary>Train, evaluate and tune your model (Step 3 of 7)</summary>
</details>

<details>
<summary>Deploy your trained model (Step 4 of 7)</summary>
</details>

<details>
<summary>Get predictions from your model (Step 5 of 7)</summary>
</details>

<details>
<summary>Monitor the ongoing predictions (Step 6 of 7)</summary>
</details>

<details>
<summary>Manage your models and versions (Step 7 of 7)</summary>
</details>
